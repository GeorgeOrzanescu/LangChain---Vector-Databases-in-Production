{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "from pydantic_core.core_schema import FieldValidationInfo\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "\n",
    "    # Throw error in case of receiving a numbered-list from API\n",
    "    @validator('words')\n",
    "    def not_start_with_number(cls, info: FieldValidationInfo):\n",
    "        for item in info.data:\n",
    "            if item[0].isnumeric():\n",
    "                raise ValueError(\"The word can not start with numbers!\")\n",
    "        return info.data\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Outputs: Each output is defined by declaring a variable with desired type, like a list of strings (: List[str]) in the sample code, or it could be a single string (: str) if you are expecting just one word/sentence as the response. Also, It is required to write a simple explanation using the Field function’s description attribute to help the model during inference. (We will see an example of having multiple outputs later in the lesson)\n",
    "Validators: It is possible to declare functions to validate the formatting. We ensure that the first character is not a number in the sample code. The function’s name is unimportant, but the @validator decorator must receive the same name as the variable you want to approve. (like @validator(’words’)) It is worth noting that the field variable inside the validator function will be a list if you specify it as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitue the specified target_word based the presented context.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model_input = prompt.format_prompt(\n",
    "\t\t\ttarget_word=\"behaviour\",\n",
    "\t\t\tcontext=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "model = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.0)\n",
    "\n",
    "output = model(model_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Suggestions(words=['conduct', 'manner', 'action', 'demeanor', 'attitude', 'activity'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langChainENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
