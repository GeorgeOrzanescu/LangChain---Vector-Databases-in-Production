{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1\n",
    "A key feature of LangChain is its support for prompts, which encompasses prompt management, prompt optimization, and a generic interface for all LLMs. The framework also provides common utilities for working with LLMs.\n",
    "\n",
    "- **ChatPromptTemplate** is used to create a structured conversation with the AI model, making it easier to manage the flow and content of the conversation\n",
    "- System and Human prompts differ in their roles and purposes when interacting with chat models. **SystemMessagePromptTemplate** provides initial instructions, context, or data for the AI model, while **HumanMessagePromptTemplate** are messages from the user that the AI model responds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOllama(model=\"llama2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are an assistant that helps users find information about movies.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"Find information about the movie {movie_title}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to_messages()\n",
    "Using the to_messages object in LangChain allows you to convert the formatted value of a chat prompt template into a list of message objects. This is useful when working with chat models, as it provides a structured way to manage the conversation and ensures that the chat model can understand the context and roles of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orzanescu/anaconda3/envs/langChainENV/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to help you find information about the movie \"Inception.\" Here are some key details and facts about the film:\n",
      "\n",
      "Title: Inception (2010)\n",
      "Director: Christopher Nolan\n",
      "Main Cast: Leonardo DiCaprio, Joseph Gordon-Levitt, Ellen Page, Tom Hardy, Ken Watanabe, Dileep Rao, Cillian Murphy\n",
      "Genre: Science Fiction, Action, Thriller\n",
      "Run Time: 148 minutes (2 hours and 28 minutes)\n",
      "Release Date: July 16, 2010 (United States)\n",
      "\n",
      "Plot Summary:\n",
      "\"Inception\" is a mind-bending sci-fi thriller that follows Cobb (Leonardo DiCaprio), a skilled thief who specializes in entering people's dreams and stealing their secrets. Cobb is offered a chance to redeem himself by performing an impossible task: planting an idea in someone's mind instead of stealing one. Cobb assembles a team of experts, including Arthur (Joseph Gordon-Levitt), Ariadne (Ellen Page), Eames (Tom Hardy), and Yusuf (Dileep Rao), to help him pull off the dangerous mission. As they delve deeper into the dream world, the team encounters unexpected challenges and must navigate through multiple levels of dreams within dreams to achieve their goal.\n",
      "\n",
      "Awards and Nominations:\n",
      "\"Inception\" was nominated for several awards, including four Academy Awards (Best Picture, Best Director, Best Original Screenplay, and Best Cinematography), as well as a Golden Globe Award for Best Motion Picture â€“ Drama. The film won the BAFTA Award for Best Film, among others.\n",
      "\n",
      "Reception:\n",
      "\"Inception\" received widespread critical acclaim for its complex plot, stunning visuals, and exceptional performances from the cast. The film holds a 87% approval rating on Rotten Tomatoes, based on 305 reviews, with an average rating of 8.1/10. The consensus states: \"Smart, visually striking, and full of mind-bending plot twists, Inception is a thought-provoking sci-fi thriller that will keep you guessing until the very end.\"\n",
      "\n",
      "Fun Facts:\n",
      "\n",
      "* The film's complex plot was inspired by director Christopher Nolan's own dreams and nightmares.\n",
      "* The movie's visual effects were created using a combination of practical and digital techniques, including miniature sets, projection mapping, and 3D printing.\n",
      "* The film's score was composed by Hans Zimmer, who has worked with Christopher Nolan on several other films, including \"The Dark Knight\" trilogy.\n",
      "* The movie's cast includes several actors who have worked together before, such as Leonardo DiCaprio and Joseph Gordon-Levitt, who appeared in \"Brick\" (2005) together.\n",
      "\n",
      "I hope this information helps! Let me know if you have any other questions about \"Inception.\"\n"
     ]
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "response = chat(chat_prompt.format_prompt(movie_title=\"Inception\").to_messages())\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 2\n",
    "\n",
    "LangChain prompts can be found in various use cases, such as summarization or question-answering chains. For example, when creating a summarization chain, LangChain enables interaction with an external data source to fetch data for use in the generation step. This could involve summarizing a lengthy piece of text or answering questions using specific data sources.\n",
    "\n",
    "- The **load_summarize_chain** function accepts an instance of the language model and returns a pre-built summarization chain.\n",
    "-  the **PyPDFLoader** class is responsible for loading PDF files and converting them into a format suitable for processing by LangChain. \n",
    "\n",
    "** *It is important to note that you need to install the pypdf package to run the following code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama2\", temperature=0) # temperature 0 because we want a deterministic result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the code uses the default summarization chain provided by the **load_summarize_chain** function. However, you can customize the summarization process by providing prompt templates.\n",
    "\n",
    "https://python.langchain.com/docs/use_cases/summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the summarization chain\n",
    "summarize_chain = load_summarize_chain(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_loader = PyPDFLoader(file_path=\"./conda-cheatsheet.pdf\")\n",
    "document = document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orzanescu/anaconda3/envs/langChainENV/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cheat sheet provides a comprehensive guide to using the conda package management tool. It covers various aspects of working with environments, channels, packages, and more. Here's a concise summary of the main points:\n",
      "\n",
      "1. Creating new environments and updating existing ones: conda create/update/remove environments, and conda config --set channel_priority to set default channel for package fetching.\n",
      "2. Working with packages: conda install/uninstall/list packages, and use conda search to get information about packages.\n",
      "3. Channel management: conda config --show-sources to view channel sources, add channels using conda config --add channels, and set default channel for package fetching using conda config --set channel_priority.\n",
      "4. Importing environments: conda env create/import -n ENVNAME --file ENV.yml/ENV.txt to import environments with Python version or platform specifics.\n",
      "5. Environment management: conda create/clone/rename/delete environments using conda remove -n ENVNAME --all, list revisions made to environment using conda list -n ENVNAME --revisions, and restore environment to a revision using conda install -n ENVNAME --revision NUMBER.\n",
      "6. Exporting environments: conda env export --from-history> ENV.yml or platform + package specific conda env export ENVNAME>ENV.yml to export environments with package and channel specifics.\n",
      "7. Additional hints: use conda COMMAND --help to get help for any command, conda search PKGNAME --info to get information about packages, and run commands without user prompt using conda COMMAND --yes to install multiple packages at once.\n",
      "8. Follow the Conda project on Twitter: @anacondainc and @condaproject for more resources and updates.\n"
     ]
    }
   ],
   "source": [
    "# Summarize the document\n",
    "summary = summarize_chain(document)\n",
    "print(summary['output_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langChainENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
