{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM example\n",
    "\n",
    "Create a PromptTemplateCopy to format the input for the model. Lastly, define an LLMChainCopy to combine the model and prompt. Run the chain with the desired input using .run(). \n",
    "\n",
    "- *Remember to install the required packages with the following command: pip install langchain==0.1.4 deeplake openai==1.10.0 tiktokenCopy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "  input_variables=[\"product\"],\n",
    "  template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orzanescu/anaconda3/envs/langChainENV/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coming up with a great name for a company that makes wireless headphones can be a challenging task, but here are some suggestions to get you started:\n",
      "\n",
      "1. SoundWave - This name plays off the idea of sound waves and conveys the idea of high-quality audio.\n",
      "2. WirelessWorld - This name emphasizes the company's focus on wireless technology and suggests a global reach.\n",
      "3. AudioFusion - This name combines the words \"audio\" and \"fusion\" to create a unique and memorable brand identity.\n",
      "4. FrequencyFiends - This name has a fun, playful tone and could appeal to customers looking for high-quality wireless headphones.\n",
      "5. SonicSphere - This name suggests a company that is focused on delivering high-quality audio in a wide range of settings.\n",
      "6. WirelessWonders - This name emphasizes the convenience and versatility of wireless headphones.\n",
      "7. AudioArmor - This name combines the words \"audio\" and \"armor\" to create a strong, protective brand identity.\n",
      "8. SoundScape - This name suggests a company that is focused on delivering a wide range of audio experiences through its wireless headphones.\n",
      "9. WirelessWanderlust - This name conveys the idea of adventure and exploration, which could appeal to customers looking for wireless headphones that can keep up with their active lifestyle.\n",
      "10. AudioAscent - This name suggests a company that is focused on delivering high-quality audio experiences through its wireless headphones.\n",
      "\n",
      "Remember, the name of your company should reflect your brand values and personality, as well as appeal to your target audience. Good luck with your new venture!\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print( chain.run(\"wireless headphones\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using ChatOpenAI with a HumanMessage: In this section, we are trying to use the LangChain library to create a chatbot that can translate an English sentence into French. This particular use case goes beyond what we covered in the previous lesson. We'll be employing multiple message types to differentiate between users' queries and system instructions instead of relying on a single prompt. This approach will enhance the model's comprehension of the given requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import (\n",
    "  HumanMessage,\n",
    "  SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOllama(model=\"llama2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orzanescu/anaconda3/envs/langChainENV/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\nBien sûr, je suis heureux de vous aider ! The translation of \"I love programming\" in French is \"J\\'aime le programming.\"')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "\tSystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "\tHumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **generate** method, you can also generate completions for multiple sets of messages. Each batch of messages can have its own SystemMessage and will perform independently. The following code shows the first set of messages translate the sentences from English to French, while the second ones do the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text='\\nBien sûr, je suis heureux de vous aider ! The translation of \"I love programming\" in French is \"J\\'aime le programming.\"', generation_info={'model': 'llama2', 'created_at': '2024-02-15T13:13:59.667480937Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 5542162524, 'load_duration': 552703, 'prompt_eval_duration': 156131000, 'eval_count': 37, 'eval_duration': 5384426000}, message=AIMessage(content='\\nBien sûr, je suis heureux de vous aider ! The translation of \"I love programming\" in French is \"J\\'aime le programming.\"'))], [ChatGeneration(text='\\nOf course! The translation of \"J\\'aime la programmation\" from French to English is:\\n\\n\"I like programming.\"', generation_info={'model': 'llama2', 'created_at': '2024-02-15T13:14:06.992786615Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 7322900428, 'load_duration': 870547, 'prompt_eval_count': 30, 'prompt_eval_duration': 2912580000, 'eval_count': 31, 'eval_duration': 4408474000}, message=AIMessage(content='\\nOf course! The translation of \"J\\'aime la programmation\" from French to English is:\\n\\n\"I like programming.\"'))]] llm_output={} run=[RunInfo(run_id=UUID('e16e6875-03a6-4bde-b2f5-c2824eed0e97')), RunInfo(run_id=UUID('359fde47-bb6c-4b24-a65a-65892f646feb'))]\n"
     ]
    }
   ],
   "source": [
    "batch_messages = [\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "  ],\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates French to English.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: J'aime la programmation.\")\n",
    "  ],\n",
    "]\n",
    "print( chat.generate(batch_messages) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langChainENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
